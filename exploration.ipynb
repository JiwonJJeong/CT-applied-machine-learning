{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "03c123ff",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "03c123ff"
      },
      "outputs": [],
      "source": [
        "# Code adapted from Machine Learning Engineering (Cornell Tech 2025)\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# --- 1. Mount Drive ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- 2. Define Paths ---\n",
        "# Path to the source code (loaders.py) - REMAINS ON DRIVE\n",
        "DRIVE_CODE_PATH = '/content/drive/MyDrive/GoogleColab/dataforsptransformer/'\n",
        "\n",
        "# Path to the zipped data file on Drive\n",
        "ZIP_SOURCE_PATH = os.path.join(DRIVE_CODE_PATH, 'crc_markers.zip')\n",
        "\n",
        "# Local disk folder where the FAST images will be unzipped\n",
        "FAST_DATA_PATH = '/content/fast_data/'\n",
        "\n",
        "# --- 3. Unzip Data (Performance Fix) ---\n",
        "if not os.path.exists(FAST_DATA_PATH):\n",
        "    print(f\"üöÄ Unzipping data from Drive to fast local disk: {FAST_DATA_PATH}\")\n",
        "    !mkdir -p \"$FAST_DATA_PATH\"\n",
        "    # The -q flag silences the output. -d sets the destination directory.\n",
        "    !unzip -q \"$ZIP_SOURCE_PATH\" -d \"$FAST_DATA_PATH\"\n",
        "\n",
        "    print(\"‚úÖ Data transfer complete. Starting new batch load test.\")\n",
        "else:\n",
        "    print(\"Fast data directory already exists.\")\n",
        "\n",
        "\n",
        "# --- 4. Set Final Variables ---\n",
        "# PROJECT_DIR for the rest of your notebook now points to the FAST images\n",
        "PROJECT_DIR = FAST_DATA_PATH\n",
        "\n",
        "# Add the Drive path for Python to find 'loaders.py' and other modules\n",
        "if DRIVE_CODE_PATH not in sys.path:\n",
        "    sys.path.append(DRIVE_CODE_PATH)\n",
        "    print(f\"‚úÖ Added {DRIVE_CODE_PATH} to Python system path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhnekRM-RKIu",
        "outputId": "801ba0c4-4efc-4ed8-91a9-0f9875f96967"
      },
      "id": "rhnekRM-RKIu",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "üöÄ Unzipping data from Drive to fast local disk: /content/fast_data/\n",
            "‚úÖ Data transfer complete. Starting new batch load test.\n",
            "‚úÖ Added /content/drive/MyDrive/GoogleColab/dataforsptransformer/ to Python system path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# This will open a 'Choose Files' button in your output cell\n",
        "# Choose train_helpers.py\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "CuzMMLdTS7Id",
        "outputId": "d8e5aefc-1923-4f69-e953-86b114860a9e"
      },
      "id": "CuzMMLdTS7Id",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8037b3a1-0868-46c1-889d-cad37837eb65\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8037b3a1-0868-46c1-889d-cad37837eb65\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data_cleaning.py to data_cleaning.py\n",
            "User uploaded file \"data_cleaning.py\" with length 5434 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 data_cleaning.py"
      ],
      "metadata": {
        "id": "OUcSDfSnS-eb"
      },
      "id": "OUcSDfSnS-eb",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/fast_data/CRC_clusters_neighborhoods_markers_cleaned.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "o00V3nvaSrEa",
        "outputId": "0fb6fc39-9e41-4e1b-8cda-50f41ec0bea1"
      },
      "id": "o00V3nvaSrEa",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CellID  ClusterID  EventID File Name  Region TMA_AB  TMA_12  Index in File  \\\n",
              "0       0      10668        0  reg001_A  reg001      A       1              0   \n",
              "1       1      10668        4  reg001_A  reg001      A       1              4   \n",
              "2       2      10668        5  reg001_A  reg001      A       1              5   \n",
              "3       3      10668        6  reg001_A  reg001      A       1              6   \n",
              "4       4      10668       30  reg001_A  reg001      A       1             30   \n",
              "\n",
              "   groups  patients  ... CD8+ICOS+  CD8+Ki67+  CD8+PD-1+  Treg-ICOS+  \\\n",
              "0       1         1  ...         0          0          0           0   \n",
              "1       1         1  ...         0          0          0           0   \n",
              "2       1         1  ...         0          0          0           0   \n",
              "3       1         1  ...         0          0          0           0   \n",
              "4       1         1  ...         0          0          0           0   \n",
              "\n",
              "   Treg-Ki67+  Treg-PD-1+  neighborhood number final  \\\n",
              "0           0           0                        9.0   \n",
              "1           0           0                        4.0   \n",
              "2           0           0                        3.0   \n",
              "3           0           0                        3.0   \n",
              "4           0           0                        4.0   \n",
              "\n",
              "           neighborhood name              GraphID  \\\n",
              "0       Granulocyte enriched  reg001_A 1 reg001 1   \n",
              "1        Macrophage enriched  reg001_A 1 reg001 1   \n",
              "2  Immune-infiltrated stroma  reg001_A 1 reg001 1   \n",
              "3  Immune-infiltrated stroma  reg001_A 1 reg001 1   \n",
              "4        Macrophage enriched  reg001_A 1 reg001 1   \n",
              "\n",
              "                                       KNN  \n",
              "0     [79342, 215276, 86261, 19386, 85435]  \n",
              "1   [209687, 147136, 231069, 61712, 50718]  \n",
              "2  [116916, 169947, 195850, 32707, 214032]  \n",
              "3    [7427, 215280, 163828, 223298, 93734]  \n",
              "4    [158193, 153016, 27846, 87820, 97886]  \n",
              "\n",
              "[5 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f4054dc-2ac3-4a9a-a847-bfb23ea711e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CellID</th>\n",
              "      <th>ClusterID</th>\n",
              "      <th>EventID</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Region</th>\n",
              "      <th>TMA_AB</th>\n",
              "      <th>TMA_12</th>\n",
              "      <th>Index in File</th>\n",
              "      <th>groups</th>\n",
              "      <th>patients</th>\n",
              "      <th>...</th>\n",
              "      <th>CD8+ICOS+</th>\n",
              "      <th>CD8+Ki67+</th>\n",
              "      <th>CD8+PD-1+</th>\n",
              "      <th>Treg-ICOS+</th>\n",
              "      <th>Treg-Ki67+</th>\n",
              "      <th>Treg-PD-1+</th>\n",
              "      <th>neighborhood number final</th>\n",
              "      <th>neighborhood name</th>\n",
              "      <th>GraphID</th>\n",
              "      <th>KNN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10668</td>\n",
              "      <td>0</td>\n",
              "      <td>reg001_A</td>\n",
              "      <td>reg001</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Granulocyte enriched</td>\n",
              "      <td>reg001_A 1 reg001 1</td>\n",
              "      <td>[79342, 215276, 86261, 19386, 85435]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10668</td>\n",
              "      <td>4</td>\n",
              "      <td>reg001_A</td>\n",
              "      <td>reg001</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Macrophage enriched</td>\n",
              "      <td>reg001_A 1 reg001 1</td>\n",
              "      <td>[209687, 147136, 231069, 61712, 50718]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>10668</td>\n",
              "      <td>5</td>\n",
              "      <td>reg001_A</td>\n",
              "      <td>reg001</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Immune-infiltrated stroma</td>\n",
              "      <td>reg001_A 1 reg001 1</td>\n",
              "      <td>[116916, 169947, 195850, 32707, 214032]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>10668</td>\n",
              "      <td>6</td>\n",
              "      <td>reg001_A</td>\n",
              "      <td>reg001</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Immune-infiltrated stroma</td>\n",
              "      <td>reg001_A 1 reg001 1</td>\n",
              "      <td>[7427, 215280, 163828, 223298, 93734]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>10668</td>\n",
              "      <td>30</td>\n",
              "      <td>reg001_A</td>\n",
              "      <td>reg001</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Macrophage enriched</td>\n",
              "      <td>reg001_A 1 reg001 1</td>\n",
              "      <td>[158193, 153016, 27846, 87820, 97886]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f4054dc-2ac3-4a9a-a847-bfb23ea711e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2f4054dc-2ac3-4a9a-a847-bfb23ea711e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2f4054dc-2ac3-4a9a-a847-bfb23ea711e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZhezhXAZcrs",
        "outputId": "1832813e-2637-4a42-e0d7-df4c0a063573"
      },
      "id": "zZhezhXAZcrs",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "XoSY-V2EbYHt",
        "outputId": "de718567-80df-4472-865c-7318127f43e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XoSY-V2EbYHt",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CellID', 'ClusterID', 'EventID', 'File Name', 'Region', 'TMA_AB',\n",
              "       'TMA_12', 'Index in File', 'groups', 'patients', 'spots',\n",
              "       'CD44 - stroma:Cyc_2_ch_2', 'FOXP3 - regulatory T cells:Cyc_2_ch_3',\n",
              "       'CD8 - cytotoxic T cells:Cyc_3_ch_2',\n",
              "       'p53 - tumor suppressor:Cyc_3_ch_3',\n",
              "       'GATA3 - Th2 helper T cells:Cyc_3_ch_4',\n",
              "       'CD45 - hematopoietic cells:Cyc_4_ch_2', 'T-bet - Th1 cells:Cyc_4_ch_3',\n",
              "       'beta-catenin - Wnt signaling:Cyc_4_ch_4', 'HLA-DR - MHC-II:Cyc_5_ch_2',\n",
              "       'PD-L1 - checkpoint:Cyc_5_ch_3', 'Ki67 - proliferation:Cyc_5_ch_4',\n",
              "       'CD45RA - naive T cells:Cyc_6_ch_2', 'CD4 - T helper cells:Cyc_6_ch_3',\n",
              "       'CD21 - DCs:Cyc_6_ch_4', 'MUC-1 - epithelia:Cyc_7_ch_2',\n",
              "       'CD30 - costimulator:Cyc_7_ch_3', 'CD2 - T cells:Cyc_7_ch_4',\n",
              "       'Vimentin - cytoplasm:Cyc_8_ch_2', 'CD20 - B cells:Cyc_8_ch_3',\n",
              "       'LAG-3 - checkpoint:Cyc_8_ch_4', 'Na-K-ATPase - membranes:Cyc_9_ch_2',\n",
              "       'CD5 - T cells:Cyc_9_ch_3', 'IDO-1 - metabolism:Cyc_9_ch_4',\n",
              "       'Cytokeratin - epithelia:Cyc_10_ch_2',\n",
              "       'CD11b - macrophages:Cyc_10_ch_3', 'CD56 - NK cells:Cyc_10_ch_4',\n",
              "       'aSMA - smooth muscle:Cyc_11_ch_2', 'BCL-2 - apoptosis:Cyc_11_ch_3',\n",
              "       'CD25 - IL-2 Ra:Cyc_11_ch_4', 'CD11c - DCs:Cyc_12_ch_3',\n",
              "       'PD-1 - checkpoint:Cyc_12_ch_4',\n",
              "       'Granzyme B - cytotoxicity:Cyc_13_ch_2', 'EGFR - signaling:Cyc_13_ch_3',\n",
              "       'VISTA - costimulator:Cyc_13_ch_4', 'CD15 - granulocytes:Cyc_14_ch_2',\n",
              "       'ICOS - costimulator:Cyc_14_ch_4',\n",
              "       'Synaptophysin - neuroendocrine:Cyc_15_ch_3',\n",
              "       'GFAP - nerves:Cyc_16_ch_2', 'CD7 - T cells:Cyc_16_ch_3',\n",
              "       'CD3 - T cells:Cyc_16_ch_4',\n",
              "       'Chromogranin A - neuroendocrine:Cyc_17_ch_2',\n",
              "       'CD163 - macrophages:Cyc_17_ch_3', 'CD45RO - memory cells:Cyc_18_ch_3',\n",
              "       'CD68 - macrophages:Cyc_18_ch_4', 'CD31 - vasculature:Cyc_19_ch_3',\n",
              "       'Podoplanin - lymphatics:Cyc_19_ch_4', 'CD34 - vasculature:Cyc_20_ch_3',\n",
              "       'CD38 - multifunctional:Cyc_20_ch_4',\n",
              "       'CD138 - plasma cells:Cyc_21_ch_3', 'cell_id:cell_id',\n",
              "       'tile_nr:tile_nr', 'X:X', 'Y:Y', 'X_withinTile:X_withinTile',\n",
              "       'Y_withinTile:Y_withinTile', 'Z:Z', 'size:size', 'HOECHST1:Cyc_1_ch_1',\n",
              "       'CDX2 - intestinal epithelia:Cyc_2_ch_4',\n",
              "       'Collagen IV - bas. memb.:Cyc_12_ch_2',\n",
              "       'CD194 - CCR4 chemokine R:Cyc_14_ch_3',\n",
              "       'MMP9 - matrix metalloproteinase:Cyc_15_ch_2',\n",
              "       'CD71 - transferrin R:Cyc_15_ch_4', 'CD57 - NK cells:Cyc_17_ch_4',\n",
              "       'MMP12 - matrix metalloproteinase:Cyc_21_ch_4', 'DRAQ5:Cyc_23_ch_4',\n",
              "       'Profile_Homogeneity:Fiter1', 'ClusterSize', 'ClusterName',\n",
              "       'neighborhood10', 'CD4+ICOS+', 'CD4+Ki67+', 'CD4+PD-1+',\n",
              "       'CD68+CD163+ICOS+', 'CD68+CD163+Ki67+', 'CD68+CD163+PD-1+',\n",
              "       'CD68+ICOS+', 'CD68+Ki67+', 'CD68+PD-1+', 'CD8+ICOS+', 'CD8+Ki67+',\n",
              "       'CD8+PD-1+', 'Treg-ICOS+', 'Treg-Ki67+', 'Treg-PD-1+',\n",
              "       'neighborhood number final', 'neighborhood name', 'GraphID', 'KNN'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIktsH28eC8t"
      },
      "id": "aIktsH28eC8t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a944e224"
      },
      "source": [
        "## Prepare Graph Data\n",
        "\n",
        "### Subtask:\n",
        "Process the `df` DataFrame to extract all necessary components for graph construction: node features (`icols`), spatial coordinates ('X:X', 'Y:Y'), node identifiers ('CellID'), graph identifiers ('GraphID'), and parse the 'KNN' column to identify neighbors. Also, define a node-level target label, for example, using the 'ClusterID' column.\n"
      ],
      "id": "a944e224"
    },
    {
      "cell_type": "code",
      "source": [
        "icols = ['CD44 - stroma:Cyc_2_ch_2', 'FOXP3 - regulatory T cells:Cyc_2_ch_3',\n",
        "'CD8 - cytotoxic T cells:Cyc_3_ch_2', 'p53 - tumor suppressor:Cyc_3_ch_3',\n",
        "'GATA3 - Th2 helper T cells:Cyc_3_ch_4', 'CD45 - hematopoietic cells:Cyc_4_ch_2',\n",
        "'T-bet - Th1 cells:Cyc_4_ch_3', 'beta-catenin - Wnt signaling:Cyc_4_ch_4',\n",
        "'HLA-DR - MHC-II:Cyc_5_ch_2', 'PD-L1 - checkpoint:Cyc_5_ch_3',\n",
        "'Ki67 - proliferation:Cyc_5_ch_4', 'CD45RA - naive T cells:Cyc_6_ch_2',\n",
        "'CD4 - T helper cells:Cyc_6_ch_3', 'CD21 - DCs:Cyc_6_ch_4', 'MUC-1 - epithelia:Cyc_7_ch_2',\n",
        "'CD30 - costimulator:Cyc_7_ch_3', 'CD2 - T cells:Cyc_7_ch_4', 'Vimentin - cytoplasm:Cyc_8_ch_2',\n",
        "'CD20 - B cells:Cyc_8_ch_3', 'LAG-3 - checkpoint:Cyc_8_ch_4', 'Na-K-ATPase - membranes:Cyc_9_ch_2',\n",
        "'CD5 - T cells:Cyc_9_ch_3', 'IDO-1 - metabolism:Cyc_9_ch_4', 'Cytokeratin - epithelia:Cyc_10_ch_2',\n",
        "'CD11b - macrophages:Cyc_10_ch_3', 'CD56 - NK cells:Cyc_10_ch_4', 'aSMA - smooth muscle:Cyc_11_ch_2',\n",
        "'BCL-2 - apoptosis:Cyc_11_ch_3', 'CD25 - IL-2 Ra:Cyc_11_ch_4', 'CD11c - DCs:Cyc_12_ch_3',\n",
        "'PD-1 - checkpoint:Cyc_12_ch_4', 'Granzyme B - cytotoxicity:Cyc_13_ch_2',\n",
        "'EGFR - signaling:Cyc_13_ch_3', 'VISTA - costimulator:Cyc_13_ch_4',\n",
        "'CD15 - granulocytes:Cyc_14_ch_2', 'ICOS - costimulator:Cyc_14_ch_4',\n",
        "'Synaptophysin - neuroendocrine:Cyc_15_ch_3', 'GFAP - nerves:Cyc_16_ch_2',\n",
        "'CD7 - T cells:Cyc_16_ch_3', 'CD3 - T cells:Cyc_16_ch_4', 'Chromogranin A - neuroendocrine:Cyc_17_ch_2',\n",
        "'CD163 - macrophages:Cyc_17_ch_3', 'CD45RO - memory cells:Cyc_18_ch_3', 'CD68 - macrophages:Cyc_18_ch_4',\n",
        "'CD31 - vasculature:Cyc_19_ch_3', 'Podoplanin - lymphatics:Cyc_19_ch_4', 'CD34 - vasculature:Cyc_20_ch_3',\n",
        "'CD38 - multifunctional:Cyc_20_ch_4', 'CD138 - plasma cells:Cyc_21_ch_3', 'KNN', 'GraphID', 'X:X', 'Y:Y', 'Z:Z' ,'size:size']"
      ],
      "metadata": {
        "id": "XUyeyUmnxvMn"
      },
      "id": "XUyeyUmnxvMn",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "56421637",
        "outputId": "5d6f976c-4afc-4f30-93da-a61034ec1484"
      },
      "source": [
        "non_feature_cols = ['KNN', 'GraphID', 'CellID', 'X:X', 'Y:Y', 'Z:Z', 'size:size']\n",
        "\n",
        "# Filter the global icols variable from cell XUyeyUmnxvMn\n",
        "# Note: The icols variable in the notebook context (Variable #19) is the one from XUyeyUmnxvMn\n",
        "feature_cols = [col for col in icols if col not in non_feature_cols]\n",
        "\n",
        "# Create 'node_features' column using the filtered feature_cols\n",
        "df['node_features'] = df[feature_cols].values.tolist()\n",
        "\n",
        "# Create 'pos' column with 'X:X' and 'Y:Y' coordinates\n",
        "df['pos'] = df[['X:X', 'Y:Y']].values.tolist()\n",
        "\n",
        "# Display the first few rows of the updated df DataFrame\n",
        "df.head()"
      ],
      "id": "56421637",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CellID  ClusterID  EventID File Name  Region TMA_AB  TMA_12  Index in File  \\\n",
              "0       0      10668        0  reg001_A  reg001      A       1              0   \n",
              "1       1      10668        4  reg001_A  reg001      A       1              4   \n",
              "2       2      10668        5  reg001_A  reg001      A       1              5   \n",
              "3       3      10668        6  reg001_A  reg001      A       1              6   \n",
              "4       4      10668       30  reg001_A  reg001      A       1             30   \n",
              "\n",
              "   groups  patients  ... CD8+PD-1+  Treg-ICOS+  Treg-Ki67+  Treg-PD-1+  \\\n",
              "0       1         1  ...         0           0           0           0   \n",
              "1       1         1  ...         0           0           0           0   \n",
              "2       1         1  ...         0           0           0           0   \n",
              "3       1         1  ...         0           0           0           0   \n",
              "4       1         1  ...         0           0           0           0   \n",
              "\n",
              "   neighborhood number final          neighborhood name              GraphID  \\\n",
              "0                        9.0       Granulocyte enriched  reg001_A 1 reg001 1   \n",
              "1                        4.0        Macrophage enriched  reg001_A 1 reg001 1   \n",
              "2                        3.0  Immune-infiltrated stroma  reg001_A 1 reg001 1   \n",
              "3                        3.0  Immune-infiltrated stroma  reg001_A 1 reg001 1   \n",
              "4                        4.0        Macrophage enriched  reg001_A 1 reg001 1   \n",
              "\n",
              "                                       KNN  \\\n",
              "0     [79342, 215276, 86261, 19386, 85435]   \n",
              "1   [209687, 147136, 231069, 61712, 50718]   \n",
              "2  [116916, 169947, 195850, 32707, 214032]   \n",
              "3    [7427, 215280, 163828, 223298, 93734]   \n",
              "4    [158193, 153016, 27846, 87820, 97886]   \n",
              "\n",
              "                                       node_features         pos  \n",
              "0  [1.843590736, 17.39870644, 0.0, 59.39188385, 3...   [77, 589]  \n",
              "1  [30.28452492, 18.37573814, 74.69523621, 271.42...  [106, 826]  \n",
              "2  [139.4885101, 249.7469788, 85.55697632, 705.36...  [107, 545]  \n",
              "3  [20.59688568, 81.75975799999999, 0.0, 0.0, 34....   [98, 564]  \n",
              "4  [67.32872772, 122.1954727, 11.02828407, 325.07...  [217, 329]  \n",
              "\n",
              "[5 rows x 102 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb0f21c5-88b4-44fd-813b-f33c6050038c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CellID</th>\n",
              "      <th>ClusterID</th>\n",
              "      <th>EventID</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Region</th>\n",
              "      <th>TMA_AB</th>\n",
              "      <th>TMA_12</th>\n",
              "      <th>Index in File</th>\n",
              "      <th>groups</th>\n",
              "      <th>patients</th>\n",
              "      <th>...</th>\n",
              "      <th>CD8+PD-1+</th>\n",
              "      <th>Treg-ICOS+</th>\n",
              "      <th>Treg-Ki67+</th>\n",
              "      <th>Treg-PD-1+</th>\n",
              "      <th>neighborhood number final</th>\n",
              "      <th>neighborhood name</th>\n",
              "      <th>GraphID</th>\n",
              "      <th>KNN</th>\n",
              "      <th>node_features</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10668</td>\n",
              "      <td>0</td>\n",
              "      <td>reg001_A</td>\n",
              "      <td>reg001</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Granulocyte enriched</td>\n",
              "      <td>reg001_A 1 reg001 1</td>\n",
              "      <td>[79342, 215276, 86261, 19386, 85435]</td>\n",
              "      <td>[1.843590736, 17.39870644, 0.0, 59.39188385, 3...</td>\n",
              "      <td>[77, 589]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10668</td>\n",
              "      <td>4</td>\n",
              "      <td>reg001_A</td>\n",
              "      <td>reg001</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Macrophage enriched</td>\n",
              "      <td>reg001_A 1 reg001 1</td>\n",
              "      <td>[209687, 147136, 231069, 61712, 50718]</td>\n",
              "      <td>[30.28452492, 18.37573814, 74.69523621, 271.42...</td>\n",
              "      <td>[106, 826]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>10668</td>\n",
              "      <td>5</td>\n",
              "      <td>reg001_A</td>\n",
              "      <td>reg001</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Immune-infiltrated stroma</td>\n",
              "      <td>reg001_A 1 reg001 1</td>\n",
              "      <td>[116916, 169947, 195850, 32707, 214032]</td>\n",
              "      <td>[139.4885101, 249.7469788, 85.55697632, 705.36...</td>\n",
              "      <td>[107, 545]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>10668</td>\n",
              "      <td>6</td>\n",
              "      <td>reg001_A</td>\n",
              "      <td>reg001</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Immune-infiltrated stroma</td>\n",
              "      <td>reg001_A 1 reg001 1</td>\n",
              "      <td>[7427, 215280, 163828, 223298, 93734]</td>\n",
              "      <td>[20.59688568, 81.75975799999999, 0.0, 0.0, 34....</td>\n",
              "      <td>[98, 564]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>10668</td>\n",
              "      <td>30</td>\n",
              "      <td>reg001_A</td>\n",
              "      <td>reg001</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Macrophage enriched</td>\n",
              "      <td>reg001_A 1 reg001 1</td>\n",
              "      <td>[158193, 153016, 27846, 87820, 97886]</td>\n",
              "      <td>[67.32872772, 122.1954727, 11.02828407, 325.07...</td>\n",
              "      <td>[217, 329]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 102 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb0f21c5-88b4-44fd-813b-f33c6050038c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb0f21c5-88b4-44fd-813b-f33c6050038c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb0f21c5-88b4-44fd-813b-f33c6050038c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d704f78"
      },
      "source": [
        "## Construct PyTorch Geometric Data Objects\n",
        "\n",
        "### Subtask:\n",
        "Group the prepped data by `GraphID`. For each unique `GraphID`, construct a `torch_geometric.data.Data` object. This involves: creating a mapping of `CellID`s to internal node indices for the current graph; extracting node features (`x`) using the now correctly filtered `icols` list; building the `edge_index` from the parsed `KNN` lists (ensuring neighbors belong to the same graph); calculating `edge_attr` (Euclidean distances between connected nodes using 'X:X' and 'Y:Y' coordinates); and assigning node labels (`y`) based on the chosen target column (e.g., 'ClusterID').\n"
      ],
      "id": "3d704f78"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86a196ce"
      },
      "source": [
        "## Prepare Node-Level Data\n",
        "\n",
        "### Subtask:\n",
        "Confirm that the `df` DataFrame has the `node_features` column (with only the specified marker features from `feature_cols`), the `pos` column (with 'X:X' and 'Y:Y' coordinates), and the 'KNN' column parsed as actual Python lists. This re-uses the correctly prepared columns from previous steps.\n",
        "\n",
        "#### Instructions\n",
        "1. Import the `ast` module for safe evaluation of string literals.\n",
        "2. Inspect the data type of the 'KNN' column in the `df` DataFrame to confirm if it's currently a string. For example, use `df['KNN'].dtype`.\n",
        "3. If the 'KNN' column is of object type (meaning it contains strings), apply `ast.literal_eval` to each element in the 'KNN' column to convert the string representations of lists into actual Python lists.\n",
        "4. Print the data type of the 'KNN' column again and display the first few entries of the modified 'KNN' column to verify the conversion."
      ],
      "id": "86a196ce"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c4818dd",
        "outputId": "39277030-7792-463a-b2b0-31fb0d55e961"
      },
      "source": [
        "import ast\n",
        "\n",
        "# 1. Inspect the data type of the 'KNN' column\n",
        "print(f\"Original 'KNN' column dtype: {df['KNN'].dtype}\")\n",
        "\n",
        "# 2. If it's an object (likely strings), apply ast.literal_eval\n",
        "if df['KNN'].dtype == 'object':\n",
        "    # Ensure only valid list strings are processed to avoid errors with NaN or non-string values\n",
        "    df['KNN'] = df['KNN'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "    print(\"Converted 'KNN' column from string to Python list.\")\n",
        "else:\n",
        "    print(\"'KNN' column is already in the correct format (Python lists or equivalent).\")\n",
        "\n",
        "# 3. Print the new data type and display the first few entries\n",
        "print(f\"New 'KNN' column dtype: {df['KNN'].dtype}\")\n",
        "print(\"First 5 entries of 'KNN' column after processing:\")\n",
        "print(df['KNN'].head().tolist())"
      ],
      "id": "2c4818dd",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original 'KNN' column dtype: object\n",
            "Converted 'KNN' column from string to Python list.\n",
            "New 'KNN' column dtype: object\n",
            "First 5 entries of 'KNN' column after processing:\n",
            "[[79342, 215276, 86261, 19386, 85435], [209687, 147136, 231069, 61712, 50718], [116916, 169947, 195850, 32707, 214032], [7427, 215280, 163828, 223298, 93734], [158193, 153016, 27846, 87820, 97886]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a3a71f6"
      },
      "source": [
        "## Perform Node-Level Train/Val/Test Split\n",
        "\n",
        "### Subtask:\n",
        "Randomly shuffle all unique 'CellID's from the `df`. Then, split these 'CellID's into training, validation, and test sets according to the specified ratios (70/15/15). These sets of 'CellID's will define the center nodes for the ego-graphs in each respective dataset split.\n"
      ],
      "id": "7a3a71f6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0345386",
        "outputId": "e677b69a-1d83-4560-f607-bee4f6532c67"
      },
      "source": [
        "import random\n",
        "\n",
        "# 1. Extract all unique CellIDs\n",
        "all_node_ids = df['CellID'].unique().tolist()\n",
        "\n",
        "# 2. Set a random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# 3. Randomly shuffle the all_node_ids list in-place\n",
        "random.shuffle(all_node_ids)\n",
        "\n",
        "# 4. Define the split ratios\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "total_unique_nodes = len(all_node_ids)\n",
        "\n",
        "# 5. Calculate the number of CellIDs for each split\n",
        "train_split_size = int(total_unique_nodes * train_ratio)\n",
        "val_split_size = int(total_unique_nodes * val_ratio)\n",
        "# Ensure test_split_size covers the remainder to account for rounding\n",
        "test_split_size = total_unique_nodes - train_split_size - val_split_size\n",
        "\n",
        "# 6. Divide the shuffled all_node_ids list into three new lists\n",
        "train_node_ids = all_node_ids[:train_split_size]\n",
        "val_node_ids = all_node_ids[train_split_size : train_split_size + val_split_size]\n",
        "test_node_ids = all_node_ids[train_split_size + val_split_size :]\n",
        "\n",
        "# 7. Print the total number of unique CellIDs and the size of each resulting split\n",
        "print(f\"Total unique CellIDs: {total_unique_nodes}\")\n",
        "print(f\"Train node IDs split size: {len(train_node_ids)}\")\n",
        "print(f\"Validation node IDs split size: {len(val_node_ids)}\")\n",
        "print(f\"Test node IDs split size: {len(test_node_ids)}\")"
      ],
      "id": "d0345386",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique CellIDs: 258385\n",
            "Train node IDs split size: 180869\n",
            "Validation node IDs split size: 38757\n",
            "Test node IDs split size: 38759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f4dbac6"
      },
      "source": [
        "## Construct Ego-Graphs for Each Split\n",
        "\n",
        "### Subtask:\n",
        "For each 'CellID' in the `train_node_ids`, `val_node_ids`, and `test_node_ids` lists, create a `torch_geometric.data.Data` object representing an ego-graph. Each ego-graph will have the current 'CellID' as its center node (index 0). Its node features (`x`), position (`pos`), and label (`y`) will be extracted. The ego-graph will also include its immediate neighbors (from the 'KNN' column) as additional nodes, along with edges and Euclidean distance-based edge attributes connecting the center node to its neighbors. Collect these ego-graph `Data` objects into `train_dataset`, `val_dataset`, and `test_dataset`.\n"
      ],
      "id": "1f4dbac6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db9f08d4",
        "outputId": "8680e64e-e113-49ea-f327-ffe6ba189c31"
      },
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "# 1. Create a dictionary mapping CellID to its row for efficient lookup\n",
        "df_indexed = df.set_index('CellID')\n",
        "print(\"Created df_indexed for efficient CellID lookup.\")\n",
        "\n",
        "# 2. Define the create_ego_graph function\n",
        "def create_ego_graph(center_node_id, df_indexed, feature_cols, target_col='ClusterID'):\n",
        "    # a. Retrieve the center node's data\n",
        "    center_node_data = df_indexed.loc[center_node_id]\n",
        "\n",
        "    # b. Get center node's features, position, and label\n",
        "    center_x = torch.tensor(center_node_data['node_features'], dtype=torch.float).unsqueeze(0)\n",
        "    center_pos = torch.tensor(center_node_data['pos'], dtype=torch.float).unsqueeze(0)\n",
        "    center_y = torch.tensor([center_node_data[target_col]], dtype=torch.long)\n",
        "\n",
        "    # c. Identify neighbors and filter out invalid ones\n",
        "    neighbors_original_ids = center_node_data['KNN']\n",
        "    valid_neighbors_original_ids = [nid for nid in neighbors_original_ids if nid in df_indexed.index]\n",
        "\n",
        "    # d. Create a list of all unique node IDs in the ego-graph (center + valid neighbors)\n",
        "    ego_graph_node_ids = [center_node_id] + valid_neighbors_original_ids\n",
        "\n",
        "    # e. Create a mapping from ego-graph node IDs to local indices\n",
        "    local_id_map = {node_id: i for i, node_id in enumerate(ego_graph_node_ids)}\n",
        "\n",
        "    # f. Populate x_ego, pos_ego, y_ego tensors for all nodes in the ego-graph\n",
        "    x_ego_list = [center_x]\n",
        "    pos_ego_list = [center_pos]\n",
        "    y_ego_list = [center_y] # y_ego is primarily the center node's label\n",
        "\n",
        "    for neighbor_id in valid_neighbors_original_ids:\n",
        "        neighbor_data = df_indexed.loc[neighbor_id]\n",
        "        x_ego_list.append(torch.tensor(neighbor_data['node_features'], dtype=torch.float).unsqueeze(0))\n",
        "        pos_ego_list.append(torch.tensor(neighbor_data['pos'], dtype=torch.float).unsqueeze(0))\n",
        "        y_ego_list.append(torch.tensor([neighbor_data[target_col]], dtype=torch.long)) # Append neighbor labels too\n",
        "\n",
        "    x_ego = torch.cat(x_ego_list, dim=0)\n",
        "    pos_ego = torch.cat(pos_ego_list, dim=0)\n",
        "    # y_ego for ego-graph is usually just the center node's label for node classification,\n",
        "    # but here we'll keep all node labels for completeness if needed later.\n",
        "    # However, for a single ego-graph, often 'y' refers to the center node's property.\n",
        "    # Let's keep it consistent by having `y` refer to the center node's label.\n",
        "    # If multiple labels are needed, it would be `y_all_nodes` or similar.\n",
        "    # For this task, we'll assign the center node's label to the ego-graph's 'y'.\n",
        "    y_ego_graph_label = center_y\n",
        "\n",
        "    # g. Construct edge_index: from center node to each neighbor\n",
        "    edge_indices = []\n",
        "    edge_attributes = []\n",
        "\n",
        "    center_local_idx = local_id_map[center_node_id]\n",
        "    center_pos_coord = pos_ego[center_local_idx]\n",
        "\n",
        "    for neighbor_id in valid_neighbors_original_ids:\n",
        "        neighbor_local_idx = local_id_map[neighbor_id]\n",
        "        neighbor_pos_coord = pos_ego[neighbor_local_idx]\n",
        "\n",
        "        # Add edge (center -> neighbor)\n",
        "        edge_indices.append([center_local_idx, neighbor_local_idx])\n",
        "        # Add edge (neighbor -> center) to make it undirected in adjacency matrix sense\n",
        "        edge_indices.append([neighbor_local_idx, center_local_idx])\n",
        "\n",
        "        # h. Calculate edge_attr (Euclidean distance) for center-neighbor edges\n",
        "        distance = euclidean(center_pos_coord, neighbor_pos_coord)\n",
        "        edge_attributes.append([distance])\n",
        "        edge_attributes.append([distance]) # For the reverse edge\n",
        "\n",
        "    if len(edge_indices) > 0:\n",
        "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attributes, dtype=torch.float)\n",
        "    else:\n",
        "        # If no neighbors, define empty tensors for edges\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 1), dtype=torch.float) # Assuming 1 feature for edge_attr\n",
        "\n",
        "    # i. Create and return a torch_geometric.data.Data object\n",
        "    data = Data(x=x_ego, edge_index=edge_index, edge_attr=edge_attr, y=y_ego_graph_label, pos=pos_ego,\n",
        "                center_node_id=torch.tensor(center_node_id, dtype=torch.long))\n",
        "    return data\n",
        "\n",
        "print(\"Defined create_ego_graph function.\")\n",
        "\n",
        "# 3. Initialize empty lists for datasets\n",
        "train_ego_dataset = []\n",
        "val_ego_dataset = []\n",
        "test_ego_dataset = []\n",
        "\n",
        "# 4. Iterate and populate datasets\n",
        "print(\"Generating train ego-graphs...\")\n",
        "for node_id in train_node_ids:\n",
        "    train_ego_dataset.append(create_ego_graph(node_id, df_indexed, feature_cols))\n",
        "\n",
        "print(\"Generating validation ego-graphs...\")\n",
        "for node_id in val_node_ids:\n",
        "    val_ego_dataset.append(create_ego_graph(node_id, df_indexed, feature_cols))\n",
        "\n",
        "print(\"Generating test ego-graphs...\")\n",
        "for node_id in test_node_ids:\n",
        "    test_ego_dataset.append(create_ego_graph(node_id, df_indexed, feature_cols))\n",
        "\n",
        "# 5. Print the sizes of the new datasets\n",
        "print(\"\\nEgo-Graph Dataset Sizes:\")\n",
        "print(f\"  Train ego-graphs: {len(train_ego_dataset)}\")\n",
        "print(f\"  Validation ego-graphs: {len(val_ego_dataset)}\")\n",
        "print(f\"  Test ego-graphs: {len(test_ego_dataset)}\")\n"
      ],
      "id": "db9f08d4",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created df_indexed for efficient CellID lookup.\n",
            "Defined create_ego_graph function.\n",
            "Generating train ego-graphs...\n",
            "Generating validation ego-graphs...\n",
            "Generating test ego-graphs...\n",
            "\n",
            "Ego-Graph Dataset Sizes:\n",
            "  Train ego-graphs: 180869\n",
            "  Validation ego-graphs: 38757\n",
            "  Test ego-graphs: 38759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "853d7fbb",
        "outputId": "f52f63e3-fdc4-4905-c035-f2a2674944de"
      },
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device, mask_ratio=0.15):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Create a mask for node features\n",
        "        mask = torch.rand(data.x.shape) < mask_ratio\n",
        "        masked_x = data.x.clone()\n",
        "        # Replace masked features with zeros or a special token (here, zeros for simplicity)\n",
        "        masked_x[mask] = 0\n",
        "\n",
        "        # Forward pass with masked features\n",
        "        output = model(masked_x, data.edge_index, data.edge_attr, data.batch)\n",
        "\n",
        "        # Calculate loss only for masked features\n",
        "        loss = criterion(output[mask], data.x[mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, criterion, device, mask_ratio=0.15):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "\n",
        "            # Create a mask for node features (same as train)\n",
        "            mask = torch.rand(data.x.shape) < mask_ratio\n",
        "            masked_x = data.x.clone()\n",
        "            masked_x[mask] = 0\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(masked_x, data.edge_index, data.edge_attr, data.batch)\n",
        "\n",
        "            # Calculate loss only for masked features\n",
        "            loss = criterion(output[mask], data.x[mask])\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "print(\"Defined train_epoch and evaluate functions.\")"
      ],
      "id": "853d7fbb",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined train_epoch and evaluate functions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67d2a25b",
        "outputId": "02e5cb47-3018-446e-b137-42108d9b3cea"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import TransformerConv\n",
        "\n",
        "print(\"Modules imported successfully.\")"
      ],
      "id": "67d2a25b",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modules imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bf3ab7a",
        "outputId": "9e9c117f-5f51-47db-d7cf-0e4198b24a61"
      },
      "source": [
        "class GraphTransformer(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads, edge_dim, num_layers=2, dropout_rate=0.5):\n",
        "        super(GraphTransformer, self).__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        # First TransformerConv layer\n",
        "        self.conv_layers.append(TransformerConv(in_channels, hidden_channels, heads=heads, edge_dim=edge_dim, dropout=dropout_rate))\n",
        "\n",
        "        # Additional TransformerConv layers (if num_layers > 1)\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.conv_layers.append(TransformerConv(hidden_channels * heads, hidden_channels, heads=heads, edge_dim=edge_dim, dropout=dropout_rate))\n",
        "\n",
        "        # Final linear layer\n",
        "        self.lin = nn.Linear(hidden_channels * heads, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
        "        for i, conv_layer in enumerate(self.conv_layers):\n",
        "            x = conv_layer(x, edge_index, edge_attr)\n",
        "            x = F.relu(x) # Apply activation function\n",
        "            if i < len(self.conv_layers) - 1: # Apply dropout to intermediate layers\n",
        "                x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        # Pass through the final linear layer\n",
        "        x = self.lin(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model with example parameters\n",
        "in_channels = len(feature_cols) # Node feature dimension\n",
        "hidden_channels = 64\n",
        "out_channels = len(feature_cols) # Output dimension matches input feature dimension for a reconstruction task example\n",
        "heads = 4 # Number of attention heads\n",
        "edge_dim = 1 # Edge attribute dimension (Euclidean distance)\n",
        "num_layers = 2 # Number of TransformerConv layers\n",
        "\n",
        "model = GraphTransformer(in_channels, hidden_channels, out_channels, heads, edge_dim, num_layers)\n",
        "\n",
        "print(f\"GraphTransformer model created with {num_layers} layers.\")\n",
        "print(model)\n"
      ],
      "id": "3bf3ab7a",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphTransformer model created with 2 layers.\n",
            "GraphTransformer(\n",
            "  (conv_layers): ModuleList(\n",
            "    (0): TransformerConv(49, 64, heads=4)\n",
            "    (1): TransformerConv(256, 64, heads=4)\n",
            "  )\n",
            "  (lin): Linear(in_features=256, out_features=49, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9108466",
        "outputId": "bb103192-16d8-4289-bbd0-213b0e56d1c3"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Instantiate the Mean Squared Error (MSE) loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define a learning rate\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Instantiate the Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(\"Loss function (criterion) and optimizer have been defined.\")"
      ],
      "id": "f9108466",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function (criterion) and optimizer have been defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "ea9dbf7e",
        "outputId": "f4231e50-6c1e-4deb-9c34-4969c781a630"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU and set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device) # Move model to the selected device\n",
        "\n",
        "# Define the number of epochs\n",
        "epochs = 50\n",
        "\n",
        "# Initialize DataLoaders for ego-graphs\n",
        "batch_size = 32 # Assuming batch_size is defined from previous steps\n",
        "\n",
        "train_ego_loader = DataLoader(train_ego_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_ego_loader = DataLoader(val_ego_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_ego_loader = DataLoader(test_ego_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Training on: {device}\")\n",
        "print(\"Starting training and evaluation loop...\")\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train_epoch(model, train_ego_loader, criterion, optimizer, device)\n",
        "    val_loss = evaluate(model, val_ego_loader, criterion, device)\n",
        "\n",
        "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "print(\"Training and evaluation loop finished.\")\n",
        "\n",
        "# Optionally, run evaluation on the test set after training\n",
        "test_loss = evaluate(model, test_ego_loader, criterion, device)\n",
        "print(f'Test Loss: {test_loss:.4f}')"
      ],
      "id": "ea9dbf7e",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on: cuda\n",
            "Starting training and evaluation loop...\n",
            "Epoch: 001, Train Loss: 402471.7387, Val Loss: 374594.5991\n",
            "Epoch: 002, Train Loss: 371664.9501, Val Loss: 349728.1523\n",
            "Epoch: 003, Train Loss: 356608.5665, Val Loss: 344695.1324\n",
            "Epoch: 004, Train Loss: 358464.5033, Val Loss: 338585.4149\n",
            "Epoch: 005, Train Loss: 351820.2312, Val Loss: 332859.1095\n",
            "Epoch: 006, Train Loss: 349812.9335, Val Loss: 325071.1947\n",
            "Epoch: 007, Train Loss: 342862.2491, Val Loss: 326380.2203\n",
            "Epoch: 008, Train Loss: 347715.5770, Val Loss: 340676.7844\n",
            "Epoch: 009, Train Loss: 340715.7379, Val Loss: 325037.9451\n",
            "Epoch: 010, Train Loss: 338340.6157, Val Loss: 335009.7777\n",
            "Epoch: 011, Train Loss: 337164.2671, Val Loss: 324600.4767\n",
            "Epoch: 012, Train Loss: 339205.7936, Val Loss: 325999.4618\n",
            "Epoch: 013, Train Loss: 338924.9218, Val Loss: 326837.9510\n",
            "Epoch: 014, Train Loss: 336175.3510, Val Loss: 322304.8555\n",
            "Epoch: 015, Train Loss: 335511.9681, Val Loss: 322050.0723\n",
            "Epoch: 016, Train Loss: 336451.3761, Val Loss: 318059.9853\n",
            "Epoch: 017, Train Loss: 335944.3952, Val Loss: 314831.3881\n",
            "Epoch: 018, Train Loss: 337588.2021, Val Loss: 317403.3518\n",
            "Epoch: 019, Train Loss: 338382.8274, Val Loss: 321482.2943\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2400466993.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ego_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ego_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2309584942.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, criterion, optimizer, device, mask_ratio)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Calculate loss only for masked features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aee9eae"
      },
      "source": [
        "### Explanation of Graph Transformer Model Inputs\n",
        "\n",
        "The `GraphTransformer` model defined above, and more generally, many PyTorch Geometric models, expect specific input tensors to represent the graph structure and its features. Here's a detailed breakdown of the inputs:\n",
        "\n",
        "1.  **`x` (Node Features)**:\n",
        "    *   **Purpose**: This tensor represents the features associated with each node in the graph. In our context, these are the various marker expressions for each cell.\n",
        "    *   **Expected Shape**: `[num_nodes, num_node_features]`, where `num_nodes` is the total number of nodes (cells) in the graph (or batch of graphs), and `num_node_features` is the dimensionality of each node's feature vector. For our model, `num_node_features` is `len(feature_cols)`, which is 62.\n",
        "    *   **Expected Data Type**: `torch.Tensor` with `dtype=torch.float`.\n",
        "\n",
        "2.  **`edge_index` (Graph Connectivity)**:\n",
        "    *   **Purpose**: This tensor defines the connections (edges) between nodes in the graph. It's typically represented in a sparse COO (coordinate) format, indicating source and target nodes for each edge.\n",
        "    *   **Expected Shape**: `[2, num_edges]`, where the first row contains the indices of the source nodes and the second row contains the indices of the target nodes for `num_edges` edges.\n",
        "    *   **Expected Data Type**: `torch.Tensor` with `dtype=torch.long`.\n",
        "\n",
        "3.  **`edge_attr` (Edge Attributes)**:\n",
        "    *   **Purpose**: This tensor represents attributes associated with each edge. In our case, this is the Euclidean distance between connected cells.\n",
        "    *   **Expected Shape**: `[num_edges, num_edge_features]`, where `num_edges` is the total number of edges and `num_edge_features` is the dimensionality of each edge's attribute vector. For our model, `num_edge_features` is 1 (the Euclidean distance).\n",
        "    *   **Expected Data Type**: `torch.Tensor` with `dtype=torch.float`.\n",
        "\n",
        "4.  **`batch` (Batch Vector)**:\n",
        "    *   **Purpose**: When processing a batch of multiple graphs simultaneously (which is common in graph neural networks to leverage GPU parallelism), the `batch` tensor is used to identify which graph each node belongs to. It maps each node to its respective graph in the batched graph structure.\n",
        "    *   **Expected Shape**: `[num_nodes]`, where `num_nodes` is the total number of nodes across all graphs in the batch.\n",
        "    *   **Expected Data Type**: `torch.Tensor` with `dtype=torch.long`.\n",
        "    *   **Note**: This `batch` vector is typically generated automatically by PyTorch Geometric's `DataLoader` when it aggregates multiple `Data` objects into a single `Batch` object for forwarding through the model. The model receives a single large graph that is a disconnected union of all individual graphs in the batch, and the `batch` vector helps the `TransformerConv` layers correctly perform computations within each individual graph."
      ],
      "id": "8aee9eae"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vTPZVK2RJQqe"
      },
      "id": "vTPZVK2RJQqe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c8644c2",
        "outputId": "c863f8be-ff9e-4ad8-c6d8-e79c61328d9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_loss = evaluate(model, val_ego_loader, criterion, device)\n",
        "print(f'Validation Loss: {val_loss:.4f}')"
      ],
      "id": "5c8644c2",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 333298.7409\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}