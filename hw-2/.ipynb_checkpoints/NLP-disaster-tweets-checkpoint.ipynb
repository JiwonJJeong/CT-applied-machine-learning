{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334da861-d7b2-4267-9cc8-613c1c36d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classification on Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4736a207-83b0-4a8c-a45f-a60ffc66c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No I don't like cold!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOOOOOOOOO! Don't do that!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No don't tell me that!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What if?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London</td>\n",
       "      <td>Birmingham Wholesale Market is ablaze BBC News...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Niall's place | SAF 12 SQUAD |</td>\n",
       "      <td>@sunkxssedharry will you wear shorts for race ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NIGERIA</td>\n",
       "      <td>#PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Live On Webcam</td>\n",
       "      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Los Angeles, Califnordia</td>\n",
       "      <td>PSA: IÛªm splitting my personalities.\\n\\n?? t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                        location  \\\n",
       "10  30     NaN                             NaN   \n",
       "11  35     NaN                             NaN   \n",
       "12  42     NaN                             NaN   \n",
       "13  43     NaN                             NaN   \n",
       "14  45     NaN                             NaN   \n",
       "15  46  ablaze                          London   \n",
       "16  47  ablaze  Niall's place | SAF 12 SQUAD |   \n",
       "17  51  ablaze                         NIGERIA   \n",
       "18  58  ablaze                  Live On Webcam   \n",
       "19  60  ablaze        Los Angeles, Califnordia   \n",
       "\n",
       "                                                 text  \n",
       "10                              No I don't like cold!  \n",
       "11                         NOOOOOOOOO! Don't do that!  \n",
       "12                             No don't tell me that!  \n",
       "13                                          What if?!  \n",
       "14                                           Awesome!  \n",
       "15  Birmingham Wholesale Market is ablaze BBC News...  \n",
       "16  @sunkxssedharry will you wear shorts for race ...  \n",
       "17  #PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...  \n",
       "18  Check these out: http://t.co/rOI2NSmEJJ http:/...  \n",
       "19  PSA: IÛªm splitting my personalities.\\n\\n?? t...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "train_presplit = pd.read_csv(\"./data-from-NLP-disaster-tweets/train.csv\")\n",
    "test = pd.read_csv(\"./data-from-NLP-disaster-tweets/test.csv\")\n",
    "print(train_presplit.shape)\n",
    "test[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eb01fd7-c477-4899-aabf-e0fa4d7d9677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n",
      "(3263, 4)\n"
     ]
    }
   ],
   "source": [
    "# Data exploration\n",
    "print(train_presplit.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a1c000b-93db-411e-824b-e277f12f50dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3271\n"
     ]
    }
   ],
   "source": [
    "# Percent of training tweets are disasters\n",
    "count_disasters = (train_presplit[\"target\"] == 1).sum()\n",
    "print(count_disasters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8a6eae-7296-48fc-a178-41af63dbda93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5329, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>1707</td>\n",
       "      <td>bridge%20collapse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>5789</td>\n",
       "      <td>hail</td>\n",
       "      <td>Carol Stream, Illinois</td>\n",
       "      <td>GREAT MICHIGAN TECHNIQUE CAMP\\nB1G THANKS TO @...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>7789</td>\n",
       "      <td>police</td>\n",
       "      <td>Houston</td>\n",
       "      <td>CNN: Tennessee movie theater shooting suspect ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>8257</td>\n",
       "      <td>rioting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Still rioting in a couple of hours left until ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>10656</td>\n",
       "      <td>wounds</td>\n",
       "      <td>Lake Highlands</td>\n",
       "      <td>Crack in the path where I wiped out this morni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            keyword                location  \\\n",
       "1186   1707  bridge%20collapse                     NaN   \n",
       "4071   5789               hail  Carol Stream, Illinois   \n",
       "5461   7789             police                Houston    \n",
       "5787   8257            rioting                     NaN   \n",
       "7445  10656             wounds          Lake Highlands   \n",
       "\n",
       "                                                   text  target  \n",
       "1186  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0  \n",
       "4071  GREAT MICHIGAN TECHNIQUE CAMP\\nB1G THANKS TO @...       1  \n",
       "5461  CNN: Tennessee movie theater shooting suspect ...       1  \n",
       "5787  Still rioting in a couple of hours left until ...       1  \n",
       "7445  Crack in the path where I wiped out this morni...       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, validate = train_test_split(\n",
    "    train_presplit, test_size=0.3, random_state=42, shuffle=True\n",
    ")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b19c5d6-6c45-4598-bc0b-1c287e2c6786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Disasters with @: 0.20666462855395903, % Nondisasters with @: 0.31391064025794563\n"
     ]
    }
   ],
   "source": [
    "# Preprocess decision-making\n",
    "# YES: Convert all words to lowercase\n",
    "# YES: Lemmatize all words\n",
    "# YES: Strip punctuation\n",
    "# YES: Strip stop words\n",
    "\n",
    "# Maybe: Strip @s\n",
    "count_ats = train_presplit[train_presplit[\"text\"].str.contains(\"@\")]\n",
    "count_ats_disaster = (count_ats[\"target\"] == 1).sum() / (train_presplit[\"target\"] == 1).sum()\n",
    "count_ats_nondisaster = (count_ats[\"target\"] == 0).sum() / (train_presplit[\"target\"] == 0).sum()\n",
    "print(f\"% Disasters with @: {count_ats_disaster}, % Nondisasters with @: {count_ats_nondisaster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b551554c-1ee3-4168-b613-f0bd525eb98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Disasters with #: 0.2675022928767961, % Nondisasters with #: 0.20405343159834177\n"
     ]
    }
   ],
   "source": [
    "# Maybe: Strip #s\n",
    "count_ats = train_presplit[train_presplit[\"text\"].str.contains(\"#\")]\n",
    "count_ats_disaster = (count_ats[\"target\"] == 1).sum() / (train_presplit[\"target\"] == 1).sum()\n",
    "count_ats_nondisaster = (count_ats[\"target\"] == 0).sum() / (train_presplit[\"target\"] == 0).sum()\n",
    "print(f\"% Disasters with #: {count_ats_disaster}, % Nondisasters with #: {count_ats_nondisaster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecaab09d-9d42-4249-8c79-ddf16830d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Disasters with Û: 0.09110363803118313, % Nondisasters with Û: 0.07231690465223399\n"
     ]
    }
   ],
   "source": [
    "# Maybe: Strip Û symbols that did not get recorded properly\n",
    "count_ats = train_presplit[train_presplit[\"text\"].str.contains(\"Û\")]\n",
    "count_ats_disaster = (count_ats[\"target\"] == 1).sum() / (train_presplit[\"target\"] == 1).sum()\n",
    "count_ats_nondisaster = (count_ats[\"target\"] == 0).sum() / (train_presplit[\"target\"] == 0).sum()\n",
    "print(f\"% Disasters with Û: {count_ats_disaster}, % Nondisasters with Û: {count_ats_nondisaster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ef439ff-d7ee-4e70-80c6-625357342875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Disasters with http: 0.6285539590339346, % Nondisasters with http: 0.35651773376324275\n"
     ]
    }
   ],
   "source": [
    "# Maybe: Strip urls\n",
    "count_ats = train_presplit[train_presplit[\"text\"].str.contains(\"http:\")]\n",
    "count_ats_disaster = (count_ats[\"target\"] == 1).sum() / (train_presplit[\"target\"] == 1).sum()\n",
    "count_ats_nondisaster = (count_ats[\"target\"] == 0).sum() / (train_presplit[\"target\"] == 0).sum()\n",
    "print(f\"% Disasters with http: {count_ats_disaster}, % Nondisasters with http: {count_ats_nondisaster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87692445-042b-4bac-bbe5-148137804a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Disasters with https: 0.040966065423417915, % Nondisasters with https: 0.06287425149700598\n"
     ]
    }
   ],
   "source": [
    "# Maybe: Strip urls HTTPS\n",
    "count_ats = train_presplit[train_presplit[\"text\"].str.contains(\"https\")]\n",
    "count_ats_disaster = (count_ats[\"target\"] == 1).sum() / (train_presplit[\"target\"] == 1).sum()\n",
    "count_ats_nondisaster = (count_ats[\"target\"] == 0).sum() / (train_presplit[\"target\"] == 0).sum()\n",
    "print(f\"% Disasters with https: {count_ats_disaster}, % Nondisasters with https: {count_ats_nondisaster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca395951-a234-4b28-b5d2-d262a9332878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final preprocess list\n",
    "# Convert all words to lowercase\n",
    "# Lemmatize all words\n",
    "# Strip punctuation (but keep @s, #s)\n",
    "# Strip stop words\n",
    "# Strip Û symbols and other non-standard characters\n",
    "# Strip link specifics BUT keep the fact that a link was included (And also distinguishing between http: and https:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "86fe4141-70c8-4f37-bedf-4b07cde5720c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/jiwonjjeong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/jiwonjjeong/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function definitions\n",
    "from nltk.stem import *\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Adapted from code generated by ChatGPT (OpenAI, 2025)\n",
    "# Prompt: \"how to use nltk stem to take a string with multiple words and convert them to the stems\"\n",
    "# Prompt: \"how to only keep abc characters in a string\"\n",
    "# Prompt: \"create a set of common stop words like the, and, or\"\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "ps = PorterStemmer()\n",
    "\n",
    "common_stops = {\n",
    "    # Standard stop words\n",
    "    \"a\", \"an\", \"the\", \"and\", \"or\", \"but\", \"if\", \"while\", \"with\",\n",
    "    \"of\", \"at\", \"by\", \"for\", \"to\", \"in\", \"on\", \"off\", \"out\", \"up\",\n",
    "    \"down\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\",\n",
    "    \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\",\n",
    "    \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\",\n",
    "    \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\",\n",
    "    \"very\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\",\n",
    "\n",
    "    # Pronouns\n",
    "    \"i\", \"me\", \"my\", \"mine\", \"you\", \"your\", \"yours\",\n",
    "    \"he\", \"him\", \"his\", \"she\", \"her\", \"they\", \"them\", \"their\",\n",
    "    \"we\", \"us\", \"our\", \"its\", \"it\",\n",
    "\n",
    "    # Auxiliary verbs\n",
    "    \"is\", \"am\", \"are\", \"was\", \"were\", \"be\", \"being\", \"been\",\n",
    "    \"do\", \"does\", \"did\", \"have\", \"has\", \"had\",\n",
    "    \"will\", \"would\", \"shall\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\",\n",
    "\n",
    "    # Informal/slang tokens from dataset\n",
    "    \"im\", \"idk\", \"u\", \"wa\", \"gon\", \"na\", \"tho\", \"thats\", \"ur\",\n",
    "\n",
    "    # Single letters/numbers that often aren't meaningful\n",
    "    \"a\", \"i\", \"u\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\",\n",
    "\n",
    "    # extra added to deal with links or that I needed to add manually\n",
    "    \":\", \"as\", \"into\", \"until\", \"among\", \"like\", \"dont\", \"from\", \"doesnt\", \"that\", \"be\", \"ha\", \"thi\",\n",
    "}\n",
    "\n",
    "def word_based_processing(text):\n",
    "    # stems text and removes common stop words\n",
    "    # and removes details of https and http links (but keeps the http or https)\n",
    "    # and removes username tags after the @ (but keeps the @)\n",
    "    temp_words = []\n",
    "    for word in text.split(\" \"):\n",
    "        if word.startswith(\"https:\"):\n",
    "            temp_words.append(word[:5])\n",
    "        elif word.startswith(\"http:\"):\n",
    "            temp_words.append(word[:4])\n",
    "        elif word.startswith(\"@\"):\n",
    "            temp_words.append(word[:1])\n",
    "        else:\n",
    "            temp_words.append(word)\n",
    "    text_links_handled = \" \".join(temp_words)\n",
    "    words = word_tokenize(text_links_handled) \n",
    "    words_processed = []\n",
    "    for word in words:\n",
    "        if isinstance(word, str):\n",
    "            stem = ps.stem(word)\n",
    "        # remove common stops and : that lingers\n",
    "        if stem not in common_stops:\n",
    "            words_processed.append(stem)\n",
    "    return \" \".join(words_processed)\n",
    "\n",
    "def filter_for_alphanumeric_and_more(text):\n",
    "    # filters to only keep a-z, 0-9, @, #, and spaces and :\n",
    "    return re.sub(r'[^a-z0-9@# :]', '', text)\n",
    "\n",
    "def preprocess(df):\n",
    "    new_df = df.copy()\n",
    "    print(\"Original:\")\n",
    "    print(new_df.head())\n",
    "    new_df[\"text\"] = new_df[\"text\"].str.lower()\n",
    "    print(\"Lowercase:\")\n",
    "    print(new_df.head())\n",
    "    new_df[\"text\"] = new_df[\"text\"].apply(filter_for_alphanumeric_and_more)\n",
    "    print(\"Filtered:\")\n",
    "    print(new_df.head())\n",
    "    new_df[\"text\"] = new_df[\"text\"].apply(word_based_processing)\n",
    "    print(\"Filtered wordbased:\")\n",
    "    print(new_df.head())\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9bf20a01-e378-4794-b33b-611a846991e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "   Id                                               text\n",
      "0   1       SOOOO PUMPED FOR ABLAZE ???? @southridgelife\n",
      "1   2  Check these out: http://t.co/rOI2NSmEJJ http:/...\n",
      "2   3  Rene Ablaze &amp; Jacinta - Secret 2k13 (Falle...\n",
      "3   4  @flowri were you marinading it or was it an ac...\n",
      "4   5  105\\t320 [IR] ICEMOON [AFTERSHOCK] | http://t....\n",
      "Lowercase:\n",
      "   Id                                               text\n",
      "0   1       soooo pumped for ablaze ???? @southridgelife\n",
      "1   2  check these out: http://t.co/roi2nsmejj http:/...\n",
      "2   3  rene ablaze &amp; jacinta - secret 2k13 (falle...\n",
      "3   4  @flowri were you marinading it or was it an ac...\n",
      "4   5  105\\t320 [ir] icemoon [aftershock] | http://t....\n",
      "Filtered:\n",
      "   Id                                               text\n",
      "0   1           soooo pumped for ablaze  @southridgelife\n",
      "1   2  check these out: http:tcoroi2nsmejj http:tco3t...\n",
      "2   3  rene ablaze amp jacinta  secret 2k13 fallen sk...\n",
      "3   4  @flowri were you marinading it or was it an ac...\n",
      "4   5  105320 ir icemoon aftershock  http:tcoynxnvvkc...\n",
      "Filtered wordbased:\n",
      "   Id                                               text\n",
      "0   1                                 soooo pump ablaz @\n",
      "1   2             check these http http http http # nsfw\n",
      "2   3  rene ablaz amp jacinta secret 2k13 fallen sky ...\n",
      "3   4                                    @ marinad accid\n",
      "4   5  105320 ir icemoon aftershock http @ # dubstep ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>soooo pump ablaz @</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>check these http http http http # nsfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>rene ablaz amp jacinta secret 2k13 fallen sky ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@ marinad accid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>105320 ir icemoon aftershock http @ # dubstep ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text\n",
       "0   1                                 soooo pump ablaz @\n",
       "1   2             check these http http http http # nsfw\n",
       "2   3  rene ablaz amp jacinta secret 2k13 fallen sky ...\n",
       "3   4                                    @ marinad accid\n",
       "4   5  105320 ir icemoon aftershock http @ # dubstep ..."
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess test\n",
    "data = {\n",
    "    \"Id\": [1,2,3,4,5],\n",
    "    \"text\": [\"SOOOO PUMPED FOR ABLAZE ???? @southridgelife\",\n",
    "             \"Check these out: http://t.co/rOI2NSmEJJ http://t.co/3Tj8ZjiN21 http://t.co/YDUiXEfIpE http://t.co/LxTjc87KLS #nsfw\",\n",
    "             \"Rene Ablaze &amp; Jacinta - Secret 2k13 (Fallen Skies Edit) - Mar 30 2013  https://t.co/7MLMsUzV1Z\",\n",
    "             \"@flowri were you marinading it or was it an accident?\",\n",
    "             \"105\t320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/yNXnvVKCDA | @djicemoon | #Dubstep #TrapMusic #DnB #EDM #Dance #IcesÛ_ http://t.co/weQPesENku\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "89bb5b3c-77dc-4dc1-8009-3caf00d3c2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "         id            keyword                location  \\\n",
      "1186   1707  bridge%20collapse                     NaN   \n",
      "4071   5789               hail  Carol Stream, Illinois   \n",
      "5461   7789             police                Houston    \n",
      "5787   8257            rioting                     NaN   \n",
      "7445  10656             wounds          Lake Highlands   \n",
      "\n",
      "                                                   text  target  \n",
      "1186  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0  \n",
      "4071  GREAT MICHIGAN TECHNIQUE CAMP\\nB1G THANKS TO @...       1  \n",
      "5461  CNN: Tennessee movie theater shooting suspect ...       1  \n",
      "5787  Still rioting in a couple of hours left until ...       1  \n",
      "7445  Crack in the path where I wiped out this morni...       0  \n",
      "Lowercase:\n",
      "         id            keyword                location  \\\n",
      "1186   1707  bridge%20collapse                     NaN   \n",
      "4071   5789               hail  Carol Stream, Illinois   \n",
      "5461   7789             police                Houston    \n",
      "5787   8257            rioting                     NaN   \n",
      "7445  10656             wounds          Lake Highlands   \n",
      "\n",
      "                                                   text  target  \n",
      "1186  ashes 2015: australiaûªs collapse at trent br...       0  \n",
      "4071  great michigan technique camp\\nb1g thanks to @...       1  \n",
      "5461  cnn: tennessee movie theater shooting suspect ...       1  \n",
      "5787  still rioting in a couple of hours left until ...       1  \n",
      "7445  crack in the path where i wiped out this morni...       0  \n",
      "Filtered:\n",
      "         id            keyword                location  \\\n",
      "1186   1707  bridge%20collapse                     NaN   \n",
      "4071   5789               hail  Carol Stream, Illinois   \n",
      "5461   7789             police                Houston    \n",
      "5787   8257            rioting                     NaN   \n",
      "7445  10656             wounds          Lake Highlands   \n",
      "\n",
      "                                                   text  target  \n",
      "1186  ashes 2015: australias collapse at trent bridg...       0  \n",
      "4071  great michigan technique campb1g thanks to @bm...       1  \n",
      "5461  cnn: tennessee movie theater shooting suspect ...       1  \n",
      "5787  still rioting in a couple of hours left until ...       1  \n",
      "7445  crack in the path where i wiped out this morni...       0  \n",
      "Filtered wordbased:\n",
      "         id            keyword                location  \\\n",
      "1186   1707  bridge%20collapse                     NaN   \n",
      "4071   5789               hail  Carol Stream, Illinois   \n",
      "5461   7789             police                Houston    \n",
      "5787   8257            rioting                     NaN   \n",
      "7445  10656             wounds          Lake Highlands   \n",
      "\n",
      "                                                   text  target  \n",
      "1186  ash 2015 australia collaps trent bridg worst h...       0  \n",
      "4071  great michigan techniqu campb1g thank @ @ @ # ...       1  \n",
      "5461  cnn tennesse movi theater shoot suspect kill p...       1  \n",
      "5787                   still riot coupl hour left class       1  \n",
      "7445  crack path wipe morn dure beach run surfac wou...       0  \n",
      "Original:\n",
      "        id      keyword               location  \\\n",
      "2644  3796  destruction                    NaN   \n",
      "2227  3185       deluge                    NaN   \n",
      "5448  7769       police                     UK   \n",
      "132    191   aftershock                    NaN   \n",
      "6845  9810       trauma  Montgomery County, MD   \n",
      "\n",
      "                                                   text  target  \n",
      "2644  So you have a new weapon that can cause un-ima...       1  \n",
      "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
      "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
      "132   Aftershock back to school kick off was great. ...       0  \n",
      "6845  in response to trauma Children of Addicts deve...       0  \n",
      "Lowercase:\n",
      "        id      keyword               location  \\\n",
      "2644  3796  destruction                    NaN   \n",
      "2227  3185       deluge                    NaN   \n",
      "5448  7769       police                     UK   \n",
      "132    191   aftershock                    NaN   \n",
      "6845  9810       trauma  Montgomery County, MD   \n",
      "\n",
      "                                                   text  target  \n",
      "2644  so you have a new weapon that can cause un-ima...       1  \n",
      "2227  the f$&amp;@ing things i do for #gishwhes just...       0  \n",
      "5448  dt @georgegalloway: rt @galloway4mayor: ûïthe...       1  \n",
      "132   aftershock back to school kick off was great. ...       0  \n",
      "6845  in response to trauma children of addicts deve...       0  \n",
      "Filtered:\n",
      "        id      keyword               location  \\\n",
      "2644  3796  destruction                    NaN   \n",
      "2227  3185       deluge                    NaN   \n",
      "5448  7769       police                     UK   \n",
      "132    191   aftershock                    NaN   \n",
      "6845  9810       trauma  Montgomery County, MD   \n",
      "\n",
      "                                                   text  target  \n",
      "2644  so you have a new weapon that can cause unimag...       1  \n",
      "2227  the famp@ing things i do for #gishwhes just go...       0  \n",
      "5448  dt @georgegalloway: rt @galloway4mayor: the co...       1  \n",
      "132   aftershock back to school kick off was great i...       0  \n",
      "6845  in response to trauma children of addicts deve...       0  \n",
      "Filtered wordbased:\n",
      "        id      keyword               location  \\\n",
      "2644  3796  destruction                    NaN   \n",
      "2227  3185       deluge                    NaN   \n",
      "5448  7769       police                     UK   \n",
      "132    191   aftershock                    NaN   \n",
      "6845  9810       trauma  Montgomery County, MD   \n",
      "\n",
      "                                                   text  target  \n",
      "2644                  new weapon caus unimagin destruct       1  \n",
      "2227  famp @ ing thing # gishwh got soak delug go pa...       0  \n",
      "5448  dt @ rt @ col polic catch pickpocket liverpool...       1  \n",
      "132   aftershock back school kick great want thank e...       0  \n",
      "6845  respons trauma children addict develop defens ...       0  \n",
      "Original:\n",
      "   id keyword location                                               text\n",
      "0   0     NaN      NaN                 Just happened a terrible car crash\n",
      "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
      "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
      "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
      "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
      "Lowercase:\n",
      "   id keyword location                                               text\n",
      "0   0     NaN      NaN                 just happened a terrible car crash\n",
      "1   2     NaN      NaN  heard about #earthquake is different cities, s...\n",
      "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
      "3   9     NaN      NaN           apocalypse lighting. #spokane #wildfires\n",
      "4  11     NaN      NaN      typhoon soudelor kills 28 in china and taiwan\n",
      "Filtered:\n",
      "   id keyword location                                               text\n",
      "0   0     NaN      NaN                 just happened a terrible car crash\n",
      "1   2     NaN      NaN  heard about #earthquake is different cities st...\n",
      "2   3     NaN      NaN  there is a forest fire at spot pond geese are ...\n",
      "3   9     NaN      NaN            apocalypse lighting #spokane #wildfires\n",
      "4  11     NaN      NaN      typhoon soudelor kills 28 in china and taiwan\n",
      "Filtered wordbased:\n",
      "   id keyword location                                               text\n",
      "0   0     NaN      NaN                           happen terribl car crash\n",
      "1   2     NaN      NaN  heard about # earthquak differ citi stay safe ...\n",
      "2   3     NaN      NaN  forest fire spot pond gees flee across street ...\n",
      "3   9     NaN      NaN                 apocalyps light # spokan # wildfir\n",
      "4  11     NaN      NaN              typhoon soudelor kill 28 china taiwan\n"
     ]
    }
   ],
   "source": [
    "# Preprocess all and save\n",
    "preprocess(train).to_csv(\"data-from-NLP-disaster-tweets/preprocessed/train.csv\", index=False)\n",
    "preprocess(validate).to_csv(\"data-from-NLP-disaster-tweets/preprocessed/validate.csv\", index=False)\n",
    "preprocess(test).to_csv(\"data-from-NLP-disaster-tweets/preprocessed/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e645cec3-1e9c-4def-ab40-33a37281835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY OF PREPROCESSING\n",
    "# Lowercase all letters\n",
    "# Only keep alphanumerics, # and @\n",
    "# Keep the http or https part of links, get rid of the rest of the link\n",
    "# Keep the @ part of @usernames, get rid of the actual username\n",
    "# Keep the # of #topics, keep both topic and # but separate them\n",
    "# Lemmatize all words\n",
    "# Remove common stop words (and, or, the ..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869dfcc-2157-4d1f-b55e-ea8147bef8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba0082-2b7b-4989-8bbe-18bf4af57ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
